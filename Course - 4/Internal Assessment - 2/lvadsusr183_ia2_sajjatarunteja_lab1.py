# -*- coding: utf-8 -*-
"""LVADSUSR183_IA2_SajjaTarunTeja_Lab1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x8rF3l-qnFbuq4RASsb59WK8FqHCcrgf
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, f1_score, recall_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("/content/winequality-red.csv")

df.head()

df.info()

df.isna().sum()

df=df.fillna(df.mean())
# Filling the Nan values with mean of their respective columns

df.isna().sum()

dups = df[df.duplicated()==True]

dups

#df=df.drop_duplicates()
# Not choosing to drop duplicates because with the duplicates the model performs better

# Outlier Treatment
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)
print(outliers)

df["quality"].unique()

# Making the Quality into 2 distinct groups
df1 = df[~outliers]

def qalass(quality):
    if quality >= 3 and quality <= 6:
        return 0
    elif quality >= 7 and quality <= 8:
        return 1
    else:
        return None
df1['quality'] = df1['quality'].apply(qalass)

quality_distribution = df1['quality'].value_counts()
print("Wine quality distribution:")
print(quality_distribution)

plt.figure(figsize=(6, 4))
quality_distribution.plot(kind='bar', color='orange')
plt.title('Wine Quality')
plt.xlabel('Quality')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

from imblearn.over_sampling import SMOTE
x = df1.drop(columns=['quality'])
y = df1['quality']
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)
smote = SMOTE(random_state=42)
xtrainre, ytrainre = smote.fit_resample(xtrain, ytrain)

selected_features = x.columns
from sklearn.metrics import classification_report

rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(xtrainre, ytrainre)

rf_predictions = rf_classifier.predict(xtest)
rf_accuracy = accuracy_score(ytest, rf_predictions)
print("Random Forest Classifier Classification Report:")
print(classification_report(ytest, rf_predictions))
print("Random Forest Classifier Accuracy:", rf_accuracy)

